%%
%% This is file `sample-authordraft.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `authordraft')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-authordraft.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf,authordraft]{acmart}

\usepackage{graphicx}
\graphicspath{ {./} }

%% NOTE that a single column version may required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
%\setcopyright{acmcopyright}
%\copyrightyear{2018}
%\acmYear{2018}
%\acmDOI{10.1145/1122445.1122456}
%
%%% These commands are for a PROCEEDINGS abstract or paper.
%\acmConference[Woodstock '18]{Woodstock '18: ACM Symposium on Neural
%  Gaze Detection}{June 03--05, 2018}{Woodstock, NY}
%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY}
%\acmPrice{15.00}
%\acmISBN{978-1-4503-XXXX-X/18/06}
%
%
%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Hunter: Using Change Point Detection to Hunt for Performance Regressions}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
%\author{Ben Trovato}
%\authornote{Both authors contributed equally to this research.}
%\email{trovato@corporation.com}
%\orcid{1234-5678-9012}
%\author{G.K.M. Tobin}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
%\affiliation{%
%  \institution{Institute for Clarity in Documentation}
%  \streetaddress{P.O. Box 1212}
%  \city{Dublin}
%  \state{Ohio}
%  \country{USA}
%  \postcode{43017-6221}
%}
%
%\author{Lars Th{\o}rv{\"a}ld}
%\affiliation{%
%  \institution{The Th{\o}rv{\"a}ld Group}
%  \streetaddress{1 Th{\o}rv{\"a}ld Circle}
%  \city{Hekla}
%  \country{Iceland}}
%\email{larst@affiliation.org}
%
%\author{Valerie B\'eranger}
%\affiliation{%
%  \institution{Inria Paris-Rocquencourt}
%  \city{Rocquencourt}
%  \country{France}
%}
%
%\author{Aparna Patel}
%\affiliation{%
% \institution{Rajiv Gandhi University}
% \streetaddress{Rono-Hills}
% \city{Doimukh}
% \state{Arunachal Pradesh}
% \country{India}}
%
%\author{Huifen Chan}
%\affiliation{%
%  \institution{Tsinghua University}
%  \streetaddress{30 Shuangqing Rd}
%  \city{Haidian Qu}
%  \state{Beijing Shi}
%  \country{China}}
%
%\author{Charles Palmer}
%\affiliation{%
%  \institution{Palmer Research Laboratories}
%  \streetaddress{8600 Datapoint Drive}
%  \city{San Antonio}
%  \state{Texas}
%  \country{USA}
%  \postcode{78229}}
%\email{cpalmer@prl.com}
%
%\author{John Smith}
%\affiliation{%
%  \institution{The Th{\o}rv{\"a}ld Group}
%  \streetaddress{1 Th{\o}rv{\"a}ld Circle}
%  \city{Hekla}
%  \country{Iceland}}
%\email{jsmith@affiliation.org}
%
%\author{Julius P. Kumquat}
%\affiliation{%
%  \institution{The Kumquat Consortium}
%  \city{New York}
%  \country{USA}}
%\email{jpkumquat@consortium.net}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Trovato and Tobin, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Change point detection has recently gained popularity as a method of detecting performance changes in software due to its ability to cope with noisy data. In this paper we present Hunter, an open-source tool that automatically detects performance regressions and improvements in time-series data. Hunter uses a modified E-divisive means algorithm to identify statistically significant changes in normally-distributed performance metrics. We describe the changes we made to the E-divisive means algorithm along with their motivation. The main change we adopted was to replace the significance test using randomized permutations with a Student's t-test, as we discovered that the randomized approach did not produce deterministic results, at least not with a reasonable number of iterations. In addition we've made tweaks that allow us to find change points the original algorithm would not, such as two nearby changes. Finally, we conclude with lessons we’ve learned supporting Hunter across teams with individual responsibility for the performance of their project.

\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
%\begin{CCSXML}
%<ccs2012>
% <concept>
%  <concept_id>10010520.10010553.10010562</concept_id>
%  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
%  <concept_significance>500</concept_significance>
% </concept>
% <concept>
%  <concept_id>10010520.10010575.10010755</concept_id>
%  <concept_desc>Computer systems organization~Redundancy</concept_desc>
%  <concept_significance>300</concept_significance>
% </concept>
% <concept>
%  <concept_id>10010520.10010553.10010554</concept_id>
%  <concept_desc>Computer systems organization~Robotics</concept_desc>
%  <concept_significance>100</concept_significance>
% </concept>
% <concept>
%  <concept_id>10003033.10003083.10003095</concept_id>
%  <concept_desc>Networks~Network reliability</concept_desc>
%  <concept_significance>100</concept_significance>
% </concept>
%</ccs2012>
%\end{CCSXML}
%
%\ccsdesc[500]{Computer systems organization~Embedded systems}
%\ccsdesc[300]{Computer systems organization~Redundancy}
%\ccsdesc{Computer systems organization~Robotics}
%\ccsdesc[100]{Networks~Network reliability}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{change point detection, performance, benchmarking, continuous integration}

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
%\begin{teaserfigure}
%  \includegraphics[width=\textwidth]{sampleteaser}
%  \caption{Seattle Mariners at Spring Training, 2010.}
%  \Description{Enjoying the baseball game from the third-base
%  seats. Ichiro Suzuki preparing to bat.}
%  \label{fig:teaser}
%\end{teaserfigure}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
Testing the performance of distributed databases, such as Apache Casandra, is an integral part of
the development process and is often incorporated into Continuous Integration pipelines where
performance tests and benchmarks can be run periodically or in response to pushing changes to source
code repositories. But given the complex nature of distributed systems, their performance is often
unstable and performance test results can fluctuate from run to run even on the same hardware. This
result instability is due to a number of factors including variability of the underlying hardware
\cite{ONLYCONSTANTISCHANGE}, background processes and CPU frequency scaling at the OS level, and
application-level request scheduling and prioritisation \cite{TALESOFTHETAIL}. All of this makes the
job of identifying whether the change in performance is the result of a software change or simply
noise from the test extremely difficult to do automatically. Threshold-based techniques are covered
in the literature, but these methods do not handle noise in benchmark data well and require that
threshold values be set per-test \cite{MONGOCPD}. Additionally, thresholds need to be periodically tuned as performance improvements are added and new baselines are established.

In the past, we have relied heavily on experienced engineers to visually inspect graphs and benchmark data to identify changes in performance. However, this suffers from a number of drawbacks including:

\begin{itemize}
\item Expert knowledge for identifying changes is difficult to teach other engineers
\item Small teams of experts have a limit on the number of tests they can inspect
\item Even experienced engineers can miss changes
\end{itemize}

Because of these drawbacks, we have recently created Hunter, an open-source tool that uses change point detection to find statistically significant changes in time-series data. Change point detection has recently gained favour as a method of coping with the inherent instability, or noise, in performance test and benchmark data \cite{MONGOCPD} and can identify both performance regressions and improvements.

Hunter was designed with the goal of eliminating the need for a dedicated group of engineers to sift through performance test results. Instead, individual teams can feed their benchmark data to a central datastore which Hunter pulls from and analyses. We use Hunter for validating multiple releases across various distributed database and streaming products which has required that we make Hunter intuitive and user-friendly for engineers that are experts in their particular area but not performance experts.

The contributions in this paper are:

\begin{itemize}
\item We present an open-source tool that can run change point detection on any time-series data containing multiple metrics in either a .CSV file or stored on a graphite server.
\item We discuss the modifications we have made to the E-divisive means algorithm to improve its performance and predictability of results.
\item We share the lessons that we have learned from running Hunter in a multi-team environment where each team is responsible for a different product and favors different benchmarks.
\end{itemize}

\section{High-Level Overview}
Hunter is a command-line tool, written in Python, that detects statistically significant changes in time-series data stored either in a CSV file or on a graphite server. It is designed to be easily integrated into build pipelines \cite{CONTINUOUSBENCHMARKING} and provide automated performance analysis that can decide whether code should be deployed to production. As well as printing change point data on the command-line, Hunter also includes support for Slack and can be configured to send results to a Slack channel.

\subsection{Data Source}
Hunter can run analysis on data pulled from a graphite server or from data contained in an CSV file. Graphite support was necessary to integrate Hunter into our testing and deployment workflow. If developers are not using graphite as their central repository of benchmark data, the CSV support provides a common denominator for feeding data to Hunter.

\subsection{Configuration}
The data sources that Hunter uses are specified in a YAML configuration file. This configuration file has sections for graphite servers, Slack tokens, and data definitions. Hunter even supports templating which allows common definitions to be reused and avoids test definition duplication. Since we routinely use Hunter on hundreds of tests and metrics, the template feature helps to keep our configuration file small. For example, we use graphite metric prefixes to group related metrics together so that all metrics for a specific Apache Cassandra version are linked by a common string.

One example of this is the test db.20k-rw-ts.fixed, a benchmark running on (Anonymised Enterprise
Database) that performs read and write operations at a fixed rate of throughput. We run this test in both
a configuration with replication factor 1 and with replication factor 3 and yet despite this
difference we can reuse around 95\% of the Hunter configuration because the metric types are the same.

Below is an example configuration file.

\begin{verbatim}
graphite:
  url: http://graphite.local
  suffixes:
    - ebdse_read.result

templates:
  common_metrics:
    metrics:
      throughput:
        scale: 1
        direction: 1
      p99:
        scale: 1.0e-6
        direction: -1

tests:
  db.20k-rw-ts.fixed:
    inherit:
    - common_metrics
    tags:
    - db.20k-rw-ts.fixed.1-bm2small-rf-1
    prefix: performance_regressions.db.20k-rw-ts.fixed

\end{verbatim}

For test data in CSV files, Hunter allows users to specify attributes of the file such as file path, which columns contain timestamps, which contains metrics, and the delimiter character used to separate fields on each line.

\subsection{Continuous Integration}
Since Hunter is a simple Python application, it has proven trivial to connect with different teams’ CI pipelines. We use a docker image to run Hunter against daily performance test results which are stored on a central graphite server. The Docker image is launched from a Jenkins job that runs once a day.

\subsection{Sending Results to Slack}
After running change point detection on a given time-series, Hunter can submit the results of its analysis to a Slack channel. We have found that this is the perfect location to notify developers of changes in performance mainly because each channel is already categorised by team or project. Developers usually triage the results of Hunter by investigating any unexpected changes in performance to identify whether there is a genuine change in performance for the product or the result was caused by noise in the workload or the platform.

Having Hunter’s results displayed in such a prominent location as Slack channels has resulted in improvements to the underlying infrastructure used to run performance tests. When test results show frequent fluctuations because of noise from the platform, one of our teams improved the stability of those platforms so that they are provided with more actionable results from Hunter.

\section{Implementation}
Hunter is built on top of the E-divisive Means algorithm available in the signal\_processing\_algorithms library from MongoDB \cite{MONGOSIG} but we have extended it in two ways to improve its efficiency (so that we can generate results faster) and to get repeatable results when performing multiple iterations on the same data set.

\subsection{E-divisive Means Algorithm}
The E-divisive means \cite{EDIV} is an offline change point detection algorithm that uses
hierarchical estimation to estimate the number and locations of change points in a distribution.
Since it’s a nonparametric method, it makes no assumptions about the underlying data distribution or
the change in distribution and is well suited for use with benchmarking data that is often
non-normal. The hierarchical aspect comes into play when deciding which collection of data points to
search for change points. E-divisive means divides the time-series into two parts and recursively
searches for change points.

Individual points are tested using a test statistic from previous change points which the literature
calls \^{q}, and the p-value of \^{q} is determined using random permutation testing which requires multiple calculations. Using random permutations comes with a performance cost and we found that detecting change points took an unreasonably long time for our data set. Additionally, because the permutations are random we found that the results of Hunter were non-deterministic and varied from run to run. It is possible to reduce the non-determinism in the results by increasing the number of permutations but this has the negative effect of increasing Hunter’s runtime. In our case running Hunter using the standard E-divisive means algorithm on hundreds of data points for a single test and single metric took 2-3 seconds. But to validate a nightly build or release, developers need the ability to run change point detection on tens of tests where each test recorded tens of metrics. This would push the runtime to several minutes, which was no longer ideal.


\subsection{Significance Testing}
When initially developing Hunter we profiled the code to understand which parts were taking the
longest to detect change points in our data. We discovered that the vast majority of the time was
spent performing significance testing. This wasn’t entirely surprising given the use of the \^{q} statistic and its reliance on random permutations. We switched to using Student’s t-test and saw the runtime of Hunter reduce by an order of magnitude as well as providing consistent results when run multiple times on the same data set. While Student’s t-test is not a robust measure of statistical significance for arbitrary data sets, it turned out it works extremely well for our scenario. 

We also tested using the Mann-Whitney U test. This would have been appealing since, unlike the
Student's t-test, it is a non-parametric test that doesn't assume the input data is normally
distributed. But it turned out to not behave very well on small amounts of data, as it requires ~30
points to be conclusive. In contrast both the original E-Divisive, and our Student's t-version, are
able to find changes in extremely short time series with only 4-7 points. Since E-Divisive is a hierarchical algorithm that splits the original time series into ever smaller windows, this is a significant difference.

\subsection{Fixed-Sized Windows}
As we began using Hunter on larger and larger data series, we discovered that change points identified in previous runs would suddenly disappear from Hunter’s results. This issue turned out to be caused by performance regressions that were fixed shortly after being introduced. This is a known issue with E-divisive means and is discussed in \cite{MONGOCPD}. Because E-divisive means divides the time series into two parts, most of the data points on either side of the split showed similar values. The algorithm therefore, by design, would treat the two nearby changes as a temporary anomaly, rather than a persistent change, and therefore filter it out. 

\begin{figure}
	\includegraphics[width=0.45\textwidth]{hunter-regr-mod}
	\caption{Temporary anomaly example}\label{Figure 1}
\end{figure}

Figure 1 illustrates this issue.

Our solution to this problem was to split the entire time series into fixed-sized windows and run the E-divisive means algorithm on each window individually. Change points that exist at window boundaries require special attention since change point detection algorithms in general are unable to identify whether the most recent point in a data series is a change point. To address this problem Hunter allows the windows to overlap and care is taken so that a change point isn’t reported multiple times because it exists in multiple windows.

\subsection{Weak Change Points}
Splitting the data series into windows partially addresses the problem of missing change points in
large data sets, but we also needed a method of forcing the E-divisive means algorithm to continue
recursively analysing the data series. The E-divisive means algorithm terminates when the
significance test, Student's t-test in Hunter, fails. If the algorithm first selects a change point with a p-value above the threshold set by the user (usually 0.05), it will terminate immediately, even if it would have detected change points below the p-value had it continued. We refer to change points that fail the significance test but would lead to other points below the p-value as weak change points.

The process of handling weak change points has two steps. First, we use a larger p-value threshold
when splitting so that it allows detection of weak change points. Second, we reevaluate the p-values and merge the split data series in a bottom-up way by removing change points that have a p-value above the smaller, user-specified threshold. We found that without forcing recursion to continue Hunter would miss some change points. Our modification results in much more accurate p-values.

Additionally, we filter out change points that show a small relative change, e.g. change points
where the difference in metric value is below 5\%. This relative threshold acts as a filter to discard change points that are not actionable, i.e. change points that are too small for developers to reproduce or verify a fix.

\section{Evaluation}
We evaluated our algorithms using benchmark data taken from a daily Gatling \cite{GATLING} performance test on (Anonymised
Enterprise Database). The benchmark data was saved to a CSV file and passed to Hunter using the
following command-line: \begin{verbatim}poetry run hunter analyse db-gatling.csv\end{verbatim}. Table Y shows the runtime for running Hunter on the benchmark data. 

The data in db-gatling.csv contains 175 entries and covers 15 months’ worth of data. There are multiple performance changes contained within, both improvements (higher throughput or lower latency) and regressions (lower throughput or higher latency).

\begin{table*}
\centering
\begin{tabular}{|c | c | c | c | c|}
\hline
Algorithm & Mean Duration & Mean 95\% CI & Change points & Change points stddev\\
\hline
Permutation & 2.221 & 2.209, 2.233 & 16 & 1.174 \\
Student's t-test & 1.863 & 1.853, 1.873 & 20 & 0 \\
Student's + Weak Change Points & 1.594 & 1.584, 1.603 & 16 & 0 \\
\hline
\end{tabular}
\end{table*}

We opted for reading the data from a CSV file to avoid network communication delays with the
graphite server influencing the duration of each run. Every algorithm was run 30 times on the same
CSV file and the mean value, along with 95\% confidence intervals,are reported in Table Y.

Since we found that the permutation algorithm produced unstable results, we have also included the average number of change points detected for each of the algorithms in Table Y as well as the standard deviations.

\subsection{Quickly Reverted Regressions}
Around 2020-10-10 on the graph in Figure 1 we can see a drop in the throughput. This performance regression was caused by a change to the way network packet decoding and processing was done in (Anonymised Enterprise DB). This problematic change was reverted on 2020-10-21 which explains why the throughput metric returns to previous values shortly after. Two red lines demarcate the data range where the regression is present. This is a known problem with change point detection and is explicitly mentioned in \cite{MONGOCPD}.

Both the Student's t-test and weak change points algorithms detected this regression and revert in each of the 30
runs through the data. The permutation based algorithm, only detected these changes for 15 of the 30
runs, or 50\% of the time.

\subsection{MongoDB Performance Test Result Dataset}

We also used the publicly available MongoDB Performance Test Result Dataset \cite{MONGODATA} to
compare the performance of E-divisive means with random permutations, and Student's t-test with and
without weak change points filtering as the statistical significance test. Since the MongoDB data
set is so large, we have only included the top 5 tests with the most data points from the legacy
data set. We also restricted the test data to just the throughput metric for a single thread count
since the number of data points varied by thread count.

\begin{table*}
\centering
\begin{tabular}{|c | c | c | c|}
\hline
Algorithm & Test name & Change points & Change points stddev\\
\hline
Permutation & Mixed.FindOneUpdateIntId-50-50 & 742 & 6.611 \\
Permutation & Mixed.FindThenUpdate-50-50 & 846 & 11.480 \\
Permutation & Remove.IntId & 587 & 8.905 \\
Permutation & Remove.IntNonIdIndex & 622 & 8.367\\
Permutation & Remove.IntNonIdNoIndex & 976 & 20.281 \\
Student's t-test & Mixed.FindOneUpdateIntId-50-50 & 957 & 0 \\
Student's t-test & Mixed.FindThenUpdate-50-50 & 1103 & 0 \\
Student's t-test & Remove.IntId & 810 & 0 \\
Student's t-test & Remove.IntNonIdIndex & 881 & 0 \\
Student's t-test & Remove.IntNonIdNoIndex & 1330 & 0 \\
Student's + Weak Change Points & Mixed.FindOneUpdateIntId-50-50 & 649 & 0 \\
Student's + Weak Change Points & Mixed.FindThenUpdate-50-50 & 764 & 0 \\
Student's + Weak Change Points & Remove.IntId & 533 & 0 \\
Student's + Weak Change Points & Remove.IntNonIdIndex & 549 & 0 \\
Student's + Weak Change Points & Remove.IntNonIdNoIndex & 654 & 0 \\
\hline
\end{tabular}
\end{table*}


\section{Lessons Learned}
We have now been operating Hunter for multiple teams for close to 6 months. In that time we’ve made a number of improvements in addition to the algorithmic changes covered in Section 3. The lessons we have learned, and the changes made in response, helped Hunter to become the de facto choice for statistical significance detection inside of Anonymised Corporation.

\subsection{More Data Points Are Better}
We originally started off with 2 weeks worth of data points. Given that performance tests were run once a day this gave us 14 data points. This decision was primarily because we wanted to avoid the delay in collecting lots of data from our graphite server. This proved to be far too few data points to get meaningful results from Hunter and we increased it to a month (around 30) by default. This wider time range has allowed Hunter to deal with noise in the results much better and now we see fewer false positive change points. We plan to experiment with data sets covering a longer period of time in the future to see whether we can reduce the false positive rate even further.

\subsection{New Change Points Matter Most}
Once a change point has been reported to a developer it does not make sense to keep reporting it. When Hunter discovers many change points, reporting them via Slack can make the results overwhelming and make it difficult for developers to analyse. Things are made worse if a change point signals a performance regression that has since been fixed because Hunter will report both the old regression and more recent improvement as separate changes.

To quieten the output of Hunter’s Slack feature, we capped results to only show change points from the last 7 days. While this does ignore valuable data because the magnitude of the change point can be updated as new data is processed, those changes are not important enough to spam everyone on the Slack channel. In the case where developers need to see the full list of results they can run Hunter manually on the data series.

\subsection{Change Point Detection Cannot Fix Noisy Data}
One of the teams using Hunter was afflicted with frequent change point messages via the Slack bot.
After investigating these change points they discovered that the performance of the application
hadn’t changed, rather the change in benchmark results was caused by unstable hardware performance
in a private data center. Changes of +- 10\% for the median latency were typical.

While Hunter can detect statistically significant changes in time series data, it is still not impervious to data that contains wildly fluctuating points such as that produced by running benchmarks on untuned hardware.

However, the fact that the team was unable to fully take advantage of Hunter motivated them to investigate
the underlying issue and then migrate their benchmarks and tests to the cloud, which was shown to
produce more repeatable results than the internal benchmarking lab hardware. After the migration,
the benchmark results were much more stable and Hunter produced far fewer false positives. Figure 2 shows benchmark data for a single Paxos-based performance test. Before running the test on the public cloud on 2021-09-18 Hunter detected 3 change points per month, on average. All of these were false positives, that is changes in results that were not caused by software or configuration modifications. After the migration Hunter hasn’t detected a single false positive.

\begin{figure}
	\includegraphics[width=0.45\textwidth]{paxos}
	\caption{Unstable performance example}
\end{figure}

\section{Related Work}
We used the work in \cite{MONGOCPD} directly when creating Hunter and the novel contributions in this paper address some of the open questions posed there. Specifically, the authors of \cite{MONGOCPD} noted the bias inherent in the E-divisive means algorithm which favours detecting change points in the center of clusters. They make up for this bias by combining change point detection with anomaly detection which can identify large changes in performance as soon as the first data point in the new series is seen. Our use of windows for analysing data series addresses this same bias without resorting to anomaly detection which lacks the same sensitivity to changes as change point detection. Additionally, we are able to detect changes sooner, usually within 1-2 days.

Continuous Benchmarking \cite{CONTINUOUSBENCHMARKING} is a common technique for ensuring the performance of a product is maintained or improved as new code is merged into the source code repository and the literature includes examples of using change point detection \cite{MONGOCYCLE} and threshold-based methods to identify changes in software performance \cite{SAP} as part of a continuous integration pipeline. Multiple change point detection algorithms can also be combined into an ensemble which can outperform the individual algorithms \cite{MSTHESIS} when identifying performance changes.

The change point detection literature is vast and \cite{SURVEYCOOK} and \cite{SELECTREVIEW} provide excellent overviews and taxonomies of online and offline, supervised vs unsupervised, change point detection algorithms. In \cite{SURVEYCOOK} in particular, online sliding window algorithms are covered in detail.

Online change point detection has also been applied to identifying changes in performance. \cite{INTERVALCPD} combines change point detection with probabilistic model checking of interval Markov chains to promptly detect changes in the parameters of software systems and verify the system’s correctness, reliability, and performance.

Running performance tests in the cloud is known to be susceptible to performance variability \cite{BIGDATA} even when running the same software on the same hardware at different times. Historical performance data can be used to predict the future performance in cloud environments and \cite{CLOUDPREDICT} explores two change point detection algorithms, robseg and breakout, to predict variability in the cloud which enables users to plan repeatable experiments. \cite{CASESTUDYCPD} uses the E-divisive means algorithm to answer the question: does performance stability of serverless applications vary over time?


\section{Conclusion}
Detecting performance regressions across a range of product versions requires automation to be able to identify them quickly and without needing expert developers to manually detect them. Change point detection has emerged as a solution to this problem because of its ability to cope with noise in the data that is inherent to performance testing.

Hunter is an open source tool that uses change point detection to automatically identify changes in
time-series data, taken from either a graphite server or CSV file, and report the presence of change
points. Hunter extends the E-divisive Means algorithm to incorporate a Student's t-test which
removes the indeterminism present in the original version and provides reproducible results every time it is run on a single data series. We also introduced a sliding window technique to detect change points that are temporally close to each other.

\section{Acknowledgments}
We are grateful to Guy Bolton King for his contributions to Hunter.

\bibliographystyle{ACM-Reference-Format}
\bibliography{hunter}

\end{document}
\endinput
