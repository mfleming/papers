@ARTICLE{Boehm,
  author = {Boehm, B.},
  title  = {Software Engineering},
  journal = {IEEE Transactions on Computers},
  volume = {C-25},
  year   = {1976},
  pages = {1226-1241}
}

@ARTICLE{MONGOCPD,
  author = {David Daly and William Brown and Henrik Ingo and Jim O’Leary and David Bradford.},
  year = {2020},
  title = {The Use of Change Point Detection to Identify Software Performance Regressions in a Continuous Integration System},
  journal = {In Proceedings of the 2020 ACM/SPEC International Conference on Performance Engineering(ICPE ’20)},
  year = {2020},
  doi = {10.1145/3358960.3375791}
}

@MISC{JEPSEN,
  author = {Kyle Kingsbury},
  title = {Distributed Systems Safety Research, Jepsen},
  url = {https://jepsen.io/},
  note = {Accessed: 2021-07-29},
}

@BOOK{CONTINUOUS,
  author    = {Jez Humble and David Farley},
  title     = {Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation},
  year      = {2010},
  publisher = {Addison-Wesley},
}

@MISC{CASSANDRASTRESS,
  author = {{Apache Cassandra}},
  title = {Cassandra Stress},
  url = {https://cassandra.apache.org/doc/latest/cassandra/tools/cassandra_stress.html},
  note = {Accessed: 2021-08-05},
}

@MISC{NOSQLBENCH,
  author = {{NoSQLBench}},
  title = {The open source nosql benchmarking suite},
  url = {https://github.com/nosqlbench/nosqlbench},
  note = {Accessed: 2021-08-05},
}

@MISC{HDRHISTOGRAM,
  author = {{HdrHistogram}},
  title = {High Dynamic Range Histogram},
  url = {http://hdrhistogram.org/},
  note = {Accessed: 2021-08-05},
}

@MISC{MUSTACHE,
  author = {{Mustache}},
  title = {Logic-less templates},
  url = {https://mustache.github.io/},
  note = {Accessed: 2021-07-28},
}

@MISC{JINJA,
  author = {{Jinja}},
  title = {Template engine for Python},
  url = {https://palletsprojects.com/p/jinja/},
  note = {Accessed: 2021-08-04},
}

@MISC{SNAKE,
  author = {{snakeyaml}},
  title = {YAML 1.1 parser and emitter for Java},
  url = {https://bitbucket.org/asomov/snakeyaml/src/master/},
  note = {Accessed: 2021-08-05},
}

@BOOK{TERRAFORM,
  author = {Brikman, Yevgeniy},
  title = {Terraform: Up \& Running: Writing Infrastructure as Code},
  year = {2019},
  publisher = {O'Reilly Media},
}

@MISC{ADELPHI,
  author = {{Adelphi}},
  title = {Automation tool for testing Cassandra OSS},
  url = {https://github.com/datastax/adelphi},
  note = {Accessed: 2021-08-05},
}

@ARTICLE{DSI,
  author = {Henrik Ingo and David Daly},
  title = {Automated System Performance Testing at MongoDB},
  journal = {In Workshop on Testing Database Systems (DBTest’20)},
  year = {2020},
  doi = {10.1145/3395032.3395323}
}

@ARTICLE{DIECAST,
  author = {Diwaker Gupta and Kashi Venkatesh Vishwanath and Marvin McNett and Amin Vahdat and Ken Yocum and Alex Snoeren and Geoffrey M. Voelker},
  title = {DieCast: Testing distributed systems with an accurate scale model},
  journal = {ACM Transactions on Computer Systems (TOCS), 29(2)},
  year = {2011},
  pages = {1-48},
}

@ARTICLE{ROCKSDB,
  author = {Zhichao Cao and Siying Dong and Sagar Vemuri and David H.C. Du},
  year = {2020},
  title = {Characterizing, Modeling, and Benchmarking RocksDB Key-Value Workloads at Facebook},
  journal = {18th USENIX Conference on File and Storage Technologies (FAST 20)},
  pages = {209-223},
}

@ARTICLE{SAP,
  author = {Kim-Thomas Rehmann and Changyun Seo and Dongwon Hwang and Binh Than Truong and Alexander Böhm and Dong Hun Lee},
  year = {2016},
  title = {Performance Monitoring in SAP HANA's Continuous Integration Process},
  journal = {ACM SIGMETRICS Performance Evaluation Review. 43},
  pages = {43-52},
  doi = {10.1145/2897356.2897362},
}

@ARTICLE{MOOSHOT,
author = {Waller, Jan and Ehmke, Nils C. and Hasselbring, Wilhelm},
title = {Including Performance Benchmarks into Continuous Integration to Enable DevOps},
year = {2015},
issue_date = {March 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {2},
issn = {0163-5948},
doi = {10.1145/2735399.2735416},
month = apr,
pages = {1–4},
numpages = {4},
keywords = {Kieker, MooBench, Jenkins}
}

@article{MOCKFOG,
   title={MockFog 2.0: Automated Execution of Fog Application Experiments in the Cloud},
   ISSN={2372-0018},
   DOI={10.1109/tcc.2021.3074988},
   journal={IEEE Transactions on Cloud Computing},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Hasenburg, Jonathan and Grambow, Martin and Bermbach, David},
   year={2021},
   pages={1–1}
}

@MISC{CHAOSMESH,
  author = {{Chaos Mesh}},
  title = {A Powerful Chaos Engineering Platform for Kubernetes},
  url = {https://chaos-mesh.org/},
  note = {Accessed: 2021-10-07},
}

@MISC{GCLOUD,
  author = {{Google Cloud SDK documentation}},
  title = {gcloud tool overview},
  url = {https://cloud.google.com/sdk/gcloud},
  note = {Accessed: 2021-10-07},
}

@MISC{PYTEST,
  author = {{pytest}},
  title = {pytest: helps you write better programs},
  url = {https://docs.pytest.org/en/6.2.x/},
  note = {Accessed: 2021-10-07},
}

@INPROCEEDINGS{ONLYCONSTANTISCHANGE,

  author={Duplyakin, Dmitry and Uta, Alexandru and Maricq, Aleksander and Ricci, Robert},

  booktitle={2020 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing (CCGRID)}, 

  title={In Datacenter Performance, The Only Constant Is Change}, 

  year={2020},

  volume={},

  number={},

  pages={370-379},

  doi={10.1109/CCGrid49817.2020.00-56}}

@proceedings{TALESOFTHETAIL,
author = {Li, Jialin and Sharma, Naveen Kr. and Ports, Dan R. K. and Gribble, Steven D.},
title = {Tales of the Tail: Hardware, OS, and Application-Level Sources of Tail Latency},
year = {2014},
isbn = {9781450332521},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2670979.2670988},
doi = {10.1145/2670979.2670988},
abstract = {Interactive services often have large-scale parallel implementations. To deliver fast
responses, the median and tail latencies of a service's components must be low. In
this paper, we explore the hardware, OS, and application-level sources of poor tail
latency in high throughput servers executing on multi-core machines.We model these
network services as a queuing system in order to establish the best-achievable latency
distribution. Using fine-grained measurements of three different servers (a null RPC
service, Memcached, and Nginx) on Linux, we then explore why these servers exhibit
significantly worse tail latencies than queuing models alone predict. The underlying
causes include interference from background processes, request re-ordering caused
by poor scheduling or constrained concurrency models, suboptimal interrupt routing,
CPU power saving mechanisms, and NUMA effects.We systematically eliminate these factors
and show that Memcached can achieve a median latency of 11 μs and a 99.9th percentile
latency of 32 μs at 80% utilization on a four-core system. In comparison, a na\"{\i}ve
deployment of Memcached at the same utilization on a single-core system has a median
latency of 100 μs and a 99.9th percentile latency of 5 ms. Finally, we demonstrate
that tradeoffs exist between throughput, energy, and tail latency.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {1–14},
numpages = {14},
keywords = {Tail latency, predictable latency},
location = {Seattle, WA, USA},
series = {SOCC '14}
}

@INPROCEEDINGS{CONTINUOUSBENCHMARKING,  author={Grambow, Martin and Lehmann, Fabian and Bermbach, David},  booktitle={2019 IEEE International Conference on Cloud Engineering (IC2E)},   title={Continuous Benchmarking: Using System Benchmarking in Build Pipelines},   year={2019},  volume={},  number={},  pages={241-246},  doi={10.1109/IC2E.2019.00039}}

@MISC{MONGOSIG,
  author = {MongoDB},
  title = {Signal Processing Algorithms},
  url = {https://github.com/mongodb/signal-processing-algorithms},
  note = {Accessed: 2021-10-13},
}

@MISC{MONGODATA,
  author = {MongoDB},
  title = {MongoDB Performance Test Result Dataset},
  url = {https://zenodo.org/record/5138516#.YW6T-erMIUH},
  note = {Accessed: 2021-10-13},
}

@MISC{GATLING,
  author = {Gatling},
  title = {Gatling Open-Source Load Testing - For DevOps and CI/CD},
  url = {https://gatling.io/},
  note = {Accessed: 2021-10-07},
}

@article{EDIV,
 ISSN = {01621459},
 URL = {http://www.jstor.org/stable/24247158},
 abstract = {Change point analysis has applications in a wide variety of fields. The general problem concerns the inference of a change in distribution for a set of time-ordered observations. Sequential detection is an online version in which new data are continually arriving and are analyzed adaptively. We are concerned with the related, but distinct, offline version, in which retrospective analysis of an entire sequence is performed. For a set of multivariate observations of arbitrary dimension, we consider nonparametric estimation of both the number of change points and the positions at which they occur. We do not make any assumptions regarding the nature of the change in distribution or any distribution assumptions beyond the existence of the ath absolute moment, for some α ∈ (0, 2). Estimation is based on hierarchical clustering and we propose both divisive and agglomerative algorithms. The divisive method is shown to provide consistent estimates of both the number and the location of change points under standard regularity assumptions. We compare the proposed approach with competing methods in a simulation study. Methods from cluster analysis are applied to assess performance and to allow simple comparisons of location estimates, even when the estimated number differs. We conclude with applications in genetics, finance, and spatio-temporal analysis. Supplementary materials for this article are available online.},
 author = {David S. Matteson and Nicholas A. James},
 journal = {Journal of the American Statistical Association},
 number = {505},
 pages = {334--345},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {A Nonparametric Approach for Multiple Change Point Analysis of Multivariate Data},
 volume = {109},
 year = {2014}
}


@inproceedings{MONGOCYCLE,
author = {Daly, David},
title = {Creating a Virtuous Cycle in Performance Testing at MongoDB},
year = {2021},
isbn = {9781450381949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3427921.3450234},
doi = {10.1145/3427921.3450234},
abstract = {It is important to detect changes in software performance during development in order
to avoid performance decreasing release to release or dealing with costly delays at
release time. Performance testing is part of the development process at MongoDB, and
integrated into our continuous integration system. We describe a set of changes to
that performance testing environment designed to improve testing effectiveness. These
changes help improve coverage, provide faster and more accurate signaling for performance
changes, and help us better understand the state of performance. In addition to each
component performing better, we believe that we have created and exploited a virtuous
cycle: performance test improvements drive impact, which drives more use, which drives
further impact and investment in improvements. Overall, MongoDB is getting faster
and we avoid shipping major performance regressions to our customers because of this
infrastructure.},
booktitle = {Proceedings of the ACM/SPEC International Conference on Performance Engineering},
pages = {33–41},
numpages = {9},
keywords = {variability, change point detection, performance, continuous integration, testing},
location = {Virtual Event, France},
series = {ICPE '21}
}

@article{MSTHESIS,
author={van der Horst, Tim},
title={Change Point Detection In Continuous Integration Performance Tests},
year={2021},
url = {https://repository.tudelft.nl/islandora/object/uuid:b9ef4b8e-a18e-40cb-b222-a4221cb22431},
note = {MSc Thesis},
}

@article{SURVEYCOOK,
author = {Aminikhanghahi, Samaneh and Cook, Diane},
year = {2017},
month = {05},
pages = {},
title = {A Survey of Methods for Time Series Change Point Detection},
volume = {51},
journal = {Knowledge and Information Systems},
doi = {10.1007/s10115-016-0987-z}
}

@article{SELECTREVIEW,
author = {Truong, Charles and Oudre, Laurent and Vayatis, Nicolas},
year = {2019},
month = {09},
pages = {107299},
title = {Selective review of offline change point detection methods},
volume = {167},
journal = {Signal Processing},
doi = {10.1016/j.sigpro.2019.107299}
}

@inproceedings{INTERVALCPD,
title = "Interval Change-Point Detection for Runtime Probabilistic Model Checking",
author = "Xingyu Zhao and Radu Calinescu and Simos Gerasimou and Valentin Robu and David Flynn",
year = "2020",
language = "English",
booktitle = "35th IEEE/ACM International Conference on Automated Software Engineering",
}

@inproceedings {BIGDATA,
author = {Alexandru Uta and Alexandru Custura and Dmitry Duplyakin and Ivo Jimenez and Jan Rellermeyer and Carlos Maltzahn and Robert Ricci and Alexandru Iosup},
title = {Is Big Data Performance Reproducible in Modern Cloud Networks? },
booktitle = {17th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 20)},
year = {2020},
isbn = {978-1-939133-13-7},
address = {Santa Clara, CA},
pages = {513--527},
url = {https://www.usenix.org/conference/nsdi20/presentation/uta},
publisher = {{USENIX} Association},
month = feb,
}

@inproceedings{CLOUDPREDICT,
author = {Zhao, Yuxuan and Duplyakin, Dmitry and Ricci, Robert and Uta, Alexandru},
title = {Cloud Performance Variability Prediction},
year = {2021},
isbn = {9781450383318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447545.3451182},
doi = {10.1145/3447545.3451182},
abstract = {Cloud computing plays an essential role in our society nowadays. Many important services
are highly dependant on the stable performance of the cloud. However, as prior work
has shown, clouds exhibit large degrees of performance variability. Next to the stochastic
variation induced by noisy neighbors, an important facet of cloud performance variability
is given by changepoints---the instances where the non-stationary performance metrics
exhibit persisting changes, which often last until subsequent changepoints occur.
Such undesirable artifacts of the unstable application performance lead to problems
with application performance evaluation and prediction efforts. Thus, characterization
and understanding of performance changepoints become important elements of studying
application performance in the cloud. In this paper, we showcase and tune two different
changepoint detection methods, as well as demonstrate how the timing of the changepoints
they identify can be predicted. We present a gradient-boosting-based prediction method,
show that it can achieve good prediction accuracy, and give advice to practitioners
on how to use our results.},
booktitle = {Companion of the ACM/SPEC International Conference on Performance Engineering},
pages = {35–40},
numpages = {6},
keywords = {performance prediction, cloud computing, performance variability},
location = {Virtual Event, France},
series = {ICPE '21}
}

@misc{CASESTUDYCPD,
      title={A Case Study on the Stability of Performance Tests for Serverless Applications}, 
      author={Simon Eismann and Diego Elias Costa and Lizhi Liao and Cor-Paul Bezemer and Weiyi Shang and André van Hoorn and Samuel Kounev},
      year={2021},
      eprint={2107.13320},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}
